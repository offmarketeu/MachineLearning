---
title: "MACHINE LEARNING- ASSIGNMENT"
output: html_document
---

```{r setup, include=FALSE}
library(caret)
library(ggplot2)
library(rpart)
library(randomForest)
knitr::opts_chunk$set(echo = TRUE)
```
## Executive Summary

With some wearable devices is possible to collect a huge amount of information about the activity based on the the self movement.
Our task is predict the class of activity based on the information collected using some technics of machine learning.


```{r echo=FALSE}

#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="trainning.csv")
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile="test.csv")

trainning<- read.csv("trainning.csv", sep=",", header=TRUE,na.strings=c("NA","#DIV/0!",""))
test<- read.csv("test.csv", sep=",", header=TRUE, na.strings=c("NA","#DIV/0!",""))

trainning$classe<- as.character(trainning$classe)
dime<-dim(trainning)
```

## Cleaning Data 

We have two files: 'trainning' and 'test' downloaded from the url https://d396qusza40orc.cloudfront.net. We perform our analysis from file 'trainning' and after that we will apply our best method on file test.
Initialy we have ```{r} print dime[1] ```  records and ```{r} print dime[2] ```

After having a glance of the information we discovered that some variables don't have reliable information sucha as NA, #DIV/0, etc. So we need to remove from our analysis reducing the number of variables.


```{r echo=FALSE}
rec<- grep("X|user_name|new_window|avg|std|amplitude|var|kurtosis|skewness|min_roll|min_pitch|min_yaw|max_roll|max_picth|max_yaw", names(trainning))
trainning<-trainning[,-rec]
test<-test[,-rec]
dim(trainning)
```

## Partition

Using the technics of cross validation, we are going to partitionate the information in two databases. With 'dtrainning' we will create the model and with 'dtesting' we are going to validate it.

```{r}
train<-createDataPartition(y=trainning$classe, p=.6, list=FALSE)
dtrainning<- trainning[train,]
dtesting<- trainning[-train,]
dtrainning$classe<- as.factor(dtrainning$classe)
dtesting$classe<- as.factor(dtesting$classe)

```


## Model 1 - Decision Tree

Our first model is Decision Tree, testing it in dtesting information we can see the accuracy generated in the confusion matrix.   

```{r}
set.seed(123456)
modfit <- rpart(classe~. , data=dtrainning, method="class")
prediction<- predict(modfit, newdata=dtesting, type="class")
confusionMatrix(prediction, dtesting$classe)

```

## Model 2 - Random Forest

Our second model is Random Forest, following the same process, with this model we improve our accuracy.

```{r}
set.seed(123456)
modfit2 <- randomForest(classe~. , data=dtrainning, type="class")
modfit2
prediction2<- predict(modfit2, newdata=dtesting)
confusionMatrix(prediction2, dtesting$classe)

```


## Conclusions


```{r}
predict_test <- predict(modfit2, newdata=test, type="class")
predict_test
```



